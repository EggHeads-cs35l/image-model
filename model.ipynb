{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version:  3.9.13 (main, Oct 13 2022, 16:12:30) \n",
      "[Clang 12.0.0 ]\n"
     ]
    }
   ],
   "source": [
    "# check versions and devices\n",
    "print(\"python version: \", sys.version)\n",
    "# print(\"tf version: \", tf.__version__)\n",
    "# print(\"devices: \", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert annotations to dataframes to visualize classes\n",
    "from pandas import DataFrame\n",
    "from scipy.io import loadmat\n",
    "mat = loadmat('data/info.mat')\n",
    "cars = DataFrame(mat['class_names'][0])\n",
    "boxes = DataFrame(mat['annotations'][0])\n",
    "# print(\"cars:\\n\", cars.head())\n",
    "# print(\"boxes:\\n\", boxes.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize images into directories\n",
    "import os\n",
    "import shutil\n",
    "imlist = os.listdir(\"./data/images/\")\n",
    "for i in range(len(imlist)):\n",
    "    img_num = int(imlist[i].split('.')[0])\n",
    "    dir_num = int(boxes['class'][img_num-1][0][0]-1)\n",
    "    img_path = os.path.join(\"./data/images/\", imlist[i])\n",
    "    dir_path = os.path.join(\"./data/dataset/\", str(dir_num)+\"/\"+imlist[i])\n",
    "    shutil.move(img_path, dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16185 files belonging to 196 classes.\n",
      "Using 12948 files for training.\n",
      "Found 16185 files belonging to 196 classes.\n",
      "Using 3237 files for validation.\n",
      "class names:  ['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "# create train and validation datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 126\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"./data/dataset/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"./data/dataset/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "# TODO: figure out why not sorted\n",
    "print(\"class names: \", class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10b546dc9a6492740535e7e359781ac3cb076df88249adf04015d7e9d7b6abb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
